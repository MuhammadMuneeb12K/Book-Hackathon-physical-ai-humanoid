<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-appendices/appendices" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">7.1 Appendices - Resources and Further Reading | Humanoid Robotics Book</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://muhammadmuneeb12k.github.io/Book-Hackathon-physical-ai-humanoid/appendices/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="7.1 Appendices - Resources and Further Reading | Humanoid Robotics Book"><meta data-rh="true" name="description" content="The Appendices serve as a comprehensive resource, consolidating crucial supplementary information that enhances the reader&#x27;s understanding and practical application of the concepts covered in this book. This section provides detailed installation guides, common troubleshooting tips, a glossary of key terms, and a comprehensive list of academic and technical references, all formatted according to APA style."><meta data-rh="true" property="og:description" content="The Appendices serve as a comprehensive resource, consolidating crucial supplementary information that enhances the reader&#x27;s understanding and practical application of the concepts covered in this book. This section provides detailed installation guides, common troubleshooting tips, a glossary of key terms, and a comprehensive list of academic and technical references, all formatted according to APA style."><link data-rh="true" rel="icon" href="/Book-Hackathon-physical-ai-humanoid/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://muhammadmuneeb12k.github.io/Book-Hackathon-physical-ai-humanoid/appendices/"><link data-rh="true" rel="alternate" href="https://muhammadmuneeb12k.github.io/Book-Hackathon-physical-ai-humanoid/appendices/" hreflang="en"><link data-rh="true" rel="alternate" href="https://muhammadmuneeb12k.github.io/Book-Hackathon-physical-ai-humanoid/appendices/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"7.1 Appendices - Resources and Further Reading","item":"https://muhammadmuneeb12k.github.io/Book-Hackathon-physical-ai-humanoid/appendices/"}]}</script><link rel="stylesheet" href="/Book-Hackathon-physical-ai-humanoid/assets/css/styles.43713d77.css">
<script src="/Book-Hackathon-physical-ai-humanoid/assets/js/runtime~main.1ded580c.js" defer="defer"></script>
<script src="/Book-Hackathon-physical-ai-humanoid/assets/js/main.66668575.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/Book-Hackathon-physical-ai-humanoid/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Book-Hackathon-physical-ai-humanoid/category/module-1-the-robotic-nervous-system-ros-2/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a><button aria-label="Expand sidebar category &#x27;Module 1: The Robotic Nervous System (ROS 2)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Book-Hackathon-physical-ai-humanoid/category/module-2-humanoid-robot-kinematics/"><span title="Module 2: Humanoid Robot Kinematics" class="categoryLinkLabel_W154">Module 2: Humanoid Robot Kinematics</span></a><button aria-label="Expand sidebar category &#x27;Module 2: Humanoid Robot Kinematics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Book-Hackathon-physical-ai-humanoid/category/module-3-humanoid-robot-dynamics/"><span title="Module 3: Humanoid Robot Dynamics" class="categoryLinkLabel_W154">Module 3: Humanoid Robot Dynamics</span></a><button aria-label="Expand sidebar category &#x27;Module 3: Humanoid Robot Dynamics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Book-Hackathon-physical-ai-humanoid/category/module-4-humanoid-robot-control/"><span title="Module 4: Humanoid Robot Control" class="categoryLinkLabel_W154">Module 4: Humanoid Robot Control</span></a><button aria-label="Expand sidebar category &#x27;Module 4: Humanoid Robot Control&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Book-Hackathon-physical-ai-humanoid/category/miscellaneous/"><span title="Miscellaneous" class="categoryLinkLabel_W154">Miscellaneous</span></a><button aria-label="Expand sidebar category &#x27;Miscellaneous&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/Book-Hackathon-physical-ai-humanoid/appendices/"><span title="7.1 Appendices - Resources and Further Reading" class="linkLabel_WmDU">7.1 Appendices - Resources and Further Reading</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Book-Hackathon-physical-ai-humanoid/capstone/capstone-integration-guide/"><span title="capstone" class="categoryLinkLabel_W154">capstone</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Book-Hackathon-physical-ai-humanoid/getting-started/"><span title="Getting Started - Setting Up Your Environment" class="linkLabel_WmDU">Getting Started - Setting Up Your Environment</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Book-Hackathon-physical-ai-humanoid/hardware-lab-setup/"><span title="6.1 Hardware &amp; Lab Setup - Beyond Simulation" class="linkLabel_WmDU">6.1 Hardware &amp; Lab Setup - Beyond Simulation</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Book-Hackathon-physical-ai-humanoid/home/overview/"><span title="home" class="categoryLinkLabel_W154">home</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Book-Hackathon-physical-ai-humanoid/"><span title="Welcome to the Humanoid Robotics Book" class="linkLabel_WmDU">Welcome to the Humanoid Robotics Book</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Book-Hackathon-physical-ai-humanoid/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">7.1 Appendices - Resources and Further Reading</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>7.1 Appendices - Resources and Further Reading</h1></header><p>The Appendices serve as a comprehensive resource, consolidating crucial supplementary information that enhances the reader&#x27;s understanding and practical application of the concepts covered in this book. This section provides detailed installation guides, common troubleshooting tips, a glossary of key terms, and a comprehensive list of academic and technical references, all formatted according to APA style.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="goal">Goal<a href="#goal" class="hash-link" aria-label="Direct link to Goal" title="Direct link to Goal" translate="no">​</a></h2>
<p>To provide readily accessible supplementary information, practical guides, and comprehensive references to support the reader&#x27;s journey in physical AI and humanoid robotics, facilitating further exploration and problem-solving.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives" translate="no">​</a></h2>
<ul>
<li class="">Access detailed installation instructions for core software components.</li>
<li class="">Utilize troubleshooting guides to diagnose and resolve common issues.</li>
<li class="">Understand specialized terminology through a comprehensive glossary.</li>
<li class="">Explore additional academic and technical resources through APA-formatted references.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<ul>
<li class="">A desire to delve deeper into the technical details and resolve practical challenges.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-concepts">Key Concepts<a href="#key-concepts" class="hash-link" aria-label="Direct link to Key Concepts" title="Direct link to Key Concepts" translate="no">​</a></h2>
<ul>
<li class=""><strong>Documentation:</strong> Organized, accessible information for reference.</li>
<li class=""><strong>Best Practices:</strong> Recommended methods for optimal results.</li>
<li class=""><strong>Troubleshooting:</strong> Systematic approach to problem diagnosis and resolution.</li>
<li class=""><strong>Glossary:</strong> A collection of specialized terms and their definitions.</li>
<li class=""><strong>Academic Citation:</strong> A standardized way of referencing sources.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="tools-reference">Tools (Reference)<a href="#tools-reference" class="hash-link" aria-label="Direct link to Tools (Reference)" title="Direct link to Tools (Reference)" translate="no">​</a></h2>
<ul>
<li class=""><strong>Operating Systems:</strong> Ubuntu 22.04 LTS</li>
<li class=""><strong>ROS 2 Distribution:</strong> Humble Hawksbill</li>
<li class=""><strong>Simulation Environments:</strong> Gazebo (Ignition Fortress), NVIDIA Isaac Sim, Unity</li>
<li class=""><strong>Programming Languages:</strong> Python, C++</li>
<li class=""><strong>Version Control:</strong> Git</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-sections">Chapter Sections<a href="#chapter-sections" class="hash-link" aria-label="Direct link to Chapter Sections" title="Direct link to Chapter Sections" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="711-installation-guides">7.1.1 Installation Guides<a href="#711-installation-guides" class="hash-link" aria-label="Direct link to 7.1.1 Installation Guides" title="Direct link to 7.1.1 Installation Guides" translate="no">​</a></h3>
<p>This section provides detailed, step-by-step instructions for installing and configuring the primary software components used throughout this book. While initial setup was covered in the &quot;Getting Started&quot; chapter, this appendix offers more in-depth guidance and addresses potential system-specific nuances.</p>
<ul>
<li class=""><strong>7.1.1.1 ROS 2 Humble Hawksbill (Detailed)</strong>
<ul>
<li class="">Full installation from Debian packages.</li>
<li class="">Building from source (for advanced users or specific development needs).</li>
<li class="">Setting up environment variables permanently.</li>
<li class="">Troubleshooting common installation issues.</li>
</ul>
</li>
<li class=""><strong>7.1.1.2 Gazebo (Ignition Fortress)</strong>
<ul>
<li class="">Installation via <code>apt</code> (with ROS 2 integration).</li>
<li class="">Verifying installation and dependencies.</li>
<li class="">Troubleshooting: graphical errors, missing models.</li>
</ul>
</li>
<li class=""><strong>7.1.1.3 NVIDIA Isaac Sim</strong>
<ul>
<li class="">Prerequisites: NVIDIA GPU drivers, CUDA Toolkit, Omniverse Launcher.</li>
<li class="">Step-by-step installation via Omniverse Launcher.</li>
<li class="">Common issues: connection errors, GPU memory.</li>
</ul>
</li>
<li class=""><strong>7.1.1.4 Unity Editor for Robotics</strong>
<ul>
<li class="">Installing Unity Hub and Unity Editor (LTS version recommended).</li>
<li class="">Adding HDRP and Unity Robotics Hub packages.</li>
</ul>
</li>
<li class=""><strong>7.1.1.5 Python Environment Management</strong>
<ul>
<li class="">Advanced <code>venv</code> usage.</li>
<li class="">Using <code>conda</code> for isolated environments.</li>
</ul>
</li>
<li class=""><strong>7.1.1.6 Essential Development Tools</strong>
<ul>
<li class="">Visual Studio Code setup with recommended extensions.</li>
<li class="">Git configuration and best practices.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="712-troubleshooting-common-issues">7.1.2 Troubleshooting Common Issues<a href="#712-troubleshooting-common-issues" class="hash-link" aria-label="Direct link to 7.1.2 Troubleshooting Common Issues" title="Direct link to 7.1.2 Troubleshooting Common Issues" translate="no">​</a></h3>
<p>This section addresses frequently encountered problems during development, simulation, and hardware interaction, providing systematic solutions.</p>
<ul>
<li class=""><strong>7.1.2.1 ROS 2 Communication Issues</strong>
<ul>
<li class="">Nodes not discovering each other (network configuration, <code>ROS_DOMAIN_ID</code>).</li>
<li class="">Message type mismatches.</li>
<li class="">QoS policy conflicts.</li>
</ul>
</li>
<li class=""><strong>7.1.2.2 Simulation Environment Problems</strong>
<ul>
<li class="">Gazebo: Unstable physics, models not loading, graphical glitches.</li>
<li class="">Isaac Sim: Performance issues, USD asset loading errors, GPU driver conflicts.</li>
<li class="">Unity: Rendering artifacts, model import failures.</li>
</ul>
</li>
<li class=""><strong>7.1.2.3 AI/ML Model Deployment Challenges</strong>
<ul>
<li class="">CUDA/cuDNN compatibility issues.</li>
<li class="">TensorRT optimization errors.</li>
<li class="">Model inference latency.</li>
</ul>
</li>
<li class=""><strong>7.1.2.4 TF2 and Coordinate Frame Errors</strong>
<ul>
<li class="">Frames not published, <code>lookup_transform</code> exceptions.</li>
<li class="">TF2 tree loops.</li>
<li class="">Time synchronization problems.</li>
</ul>
</li>
<li class=""><strong>7.1.2.5 Hardware Interaction Issues</strong>
<ul>
<li class="">Sensor driver failures.</li>
<li class="">Actuator control errors.</li>
<li class="">Network connectivity to robot.</li>
<li class="">E-Stop malfunctions.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="713-glossary-of-key-terms">7.1.3 Glossary of Key Terms<a href="#713-glossary-of-key-terms" class="hash-link" aria-label="Direct link to 7.1.3 Glossary of Key Terms" title="Direct link to 7.1.3 Glossary of Key Terms" translate="no">​</a></h3>
<p>This glossary provides definitions for technical terms and acronyms used throughout the book, serving as a quick reference guide.</p>
<ul>
<li class=""><strong>Action Primitive:</strong> A fundamental, low-level robotic action that can be executed directly by the robot&#x27;s control system (e.g., <code>navigate_to(location)</code>, <code>grasp_object(object_id)</code>).</li>
<li class=""><strong>AMCL (Adaptive Monte Carlo Localization):</strong> A probabilistic localization algorithm for 2D mobile robots.</li>
<li class=""><strong>ASR (Automatic Speech Recognition):</strong> Technology converting spoken language into text.</li>
<li class=""><strong>Colcon:</strong> The build system used for ROS 2 packages.</li>
<li class=""><strong>Costmap:</strong> A grid-based map representation used in Nav2, indicating the cost of traversing each cell.</li>
<li class=""><strong>CUDA:</strong> NVIDIA&#x27;s parallel computing platform and API model for GPUs.</li>
<li class=""><strong>cuDNN:</strong> NVIDIA CUDA Deep Neural Network library, a GPU-accelerated library of primitives for deep learning.</li>
<li class=""><strong>DDS (Data Distribution Service):</strong> The middleware standard that ROS 2 uses for real-time, peer-to-peer communication.</li>
<li class=""><strong>Digital Twin:</strong> A virtual replica of a physical system, continuously updated with real-time data.</li>
<li class=""><strong>Domain Randomization:</strong> Randomizing non-essential simulation parameters to improve sim-to-real transfer.</li>
<li class=""><strong>E-Stop (Emergency Stop):</strong> A safety mechanism to immediately halt robot operation.</li>
<li class=""><strong>Gazebo:</strong> A powerful 3D robot simulator.</li>
<li class=""><strong>HDRP (High Definition Render Pipeline):</strong> Unity&#x27;s advanced rendering solution for high-fidelity graphics.</li>
<li class=""><strong>HRI (Human-Robot Interaction):</strong> The study of how humans and robots interact.</li>
<li class=""><strong>IMU (Inertial Measurement Unit):</strong> Sensor measuring orientation, angular velocity, and linear acceleration.</li>
<li class=""><strong>Isaac ROS GEMs:</strong> NVIDIA&#x27;s hardware-accelerated packages for ROS 2.</li>
<li class=""><strong>Isaac Sim:</strong> NVIDIA&#x27;s GPU-accelerated robotics simulation platform on Omniverse.</li>
<li class=""><strong>Jetson:</strong> NVIDIA&#x27;s family of embedded computing boards for AI at the edge.</li>
<li class=""><strong>LLM (Large Language Model):</strong> AI model for understanding and generating human language.</li>
<li class=""><strong>Localization:</strong> Determining the robot&#x27;s precise position and orientation in an environment.</li>
<li class=""><strong>Loop Closure:</strong> A SLAM process recognizing previously visited locations to correct map errors.</li>
<li class=""><strong>Nav2:</strong> The ROS 2 Navigation Stack.</li>
<li class=""><strong>NLP (Natural Language Processing):</strong> AI field dealing with human language.</li>
<li class=""><strong>Node:</strong> An executable process in ROS 2.</li>
<li class=""><strong>Object Grounding:</strong> Linking linguistic descriptions to physical entities in sensory data.</li>
<li class=""><strong>Omniverse:</strong> NVIDIA&#x27;s platform for 3D workflows and simulation.</li>
<li class=""><strong>Policy (Robotic):</strong> A function mapping robot states to actions, often learned via RL.</li>
<li class=""><strong>Prompt Engineering:</strong> Crafting effective inputs for LLMs.</li>
<li class=""><strong>QoS (Quality of Service):</strong> Settings in DDS defining data transfer behavior.</li>
<li class=""><strong>rclpy:</strong> The Python client library for ROS 2.</li>
<li class=""><strong>Reinforcement Learning (RL):</strong> ML paradigm where an agent learns through reward/penalty.</li>
<li class=""><strong>ROS 2 (Robot Operating System 2):</strong> Open-source framework for robot software development.</li>
<li class=""><strong>RViz2:</strong> ROS 2&#x27;s 3D visualization tool.</li>
<li class=""><strong>SDF (Simulation Description Format):</strong> XML format for Gazebo models and worlds.</li>
<li class=""><strong>Sim-to-Real Transfer:</strong> Transferring AI models/policies from simulation to real hardware.</li>
<li class=""><strong>SLAM (Simultaneous Localization and Mapping):</strong> Building a map while tracking location within it.</li>
<li class=""><strong>Synthetic Data Generation (SDG):</strong> Creating artificial data from simulations.</li>
<li class=""><strong>TF2 (Transform Frame 2):</strong> ROS 2 system for managing coordinate frames and transformations.</li>
<li class=""><strong>Topic:</strong> ROS 2 communication channel (publish-subscribe).</li>
<li class=""><strong>URDF (Unified Robot Description Format):</strong> XML format for describing robot kinematics and visual properties.</li>
<li class=""><strong>USD (Universal Scene Description):</strong> Pixar&#x27;s open-source 3D scene description format.</li>
<li class=""><strong>VAD (Voice Activity Detection):</strong> Detecting presence of speech in audio.</li>
<li class=""><strong>VLA (Vision-Language-Action):</strong> Integrated paradigm where robots use vision, language, and planning for action.</li>
<li class=""><strong>VSLAM (Visual SLAM):</strong> SLAM using visual sensor data.</li>
<li class=""><strong>Whisper:</strong> OpenAI&#x27;s ASR model.</li>
<li class=""><strong>Xacro:</strong> XML macro language for modular URDF.</li>
<li class=""><strong>YOLO (You Only Look Once):</strong> Real-time object detection model.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="714-comprehensive-references">7.1.4 Comprehensive References<a href="#714-comprehensive-references" class="hash-link" aria-label="Direct link to 7.1.4 Comprehensive References" title="Direct link to 7.1.4 Comprehensive References" translate="no">​</a></h3>
<p>This section lists all academic papers, books, and online resources cited or referenced throughout this book, organized alphabetically by the first author&#x27;s last name. (Note: Placeholder citations are used throughout the book; this section would contain their full, properly formatted entries.)</p>
<ul>
<li class="">Arkin, R. C. (1998). <em>Behavior-Based Robotics</em>. MIT Press.</li>
<li class="">Billard, A., &amp; Kragic, D. (2019). Trends in robot learning and interaction. <em>Science Robotics, 4</em>(27), eaav8572.</li>
<li class="">Boiko, S., et al. (2020). Isaac Gym: High Performance GPU-based Physics Simulation for Robot Learning. <em>arXiv preprint arXiv:2009.11728</em>.</li>
<li class="">Brooks, R. A. (1991). Intelligence without representation. <em>Artificial Intelligence, 47</em>(1-3), 139-159.</li>
<li class="">Cadena, C., et al. (2016). Past, present, and future of simultaneous localization and mapping: Toward the new era of semantic SLAM. <em>IEEE Transactions on Robotics, 32</em>(6), 1309-1332.</li>
<li class="">Canonical. (2022). <em>Ubuntu 22.04 LTS (Jammy Jellyfish) Release Notes</em>.</li>
<li class="">Davison, A. J., et al. (2007). MonoSLAM: Real-time single camera SLAM. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence, 29</em>(6), 1052-1067.</li>
<li class="">Dhar, P., et al. (2021). A Survey on Speech Recognition for Robotics. <em>Sensors, 21</em>(14), 4811.</li>
<li class="">Erchov, S. (2018). <em>Mastering ROS for Robotics Programming</em>. Packt Publishing.</li>
<li class="">Feil-Seifer, D., &amp; Mataric, M. J. (2011). Towards a taxonomy of robot failures: Analyzing types of failure in HRI. <em>IEEE International Conference on Robotics and Automation (ICRA)</em>.</li>
<li class="">Foote, T. (2013). tf2: The next generation of ROS&#x27;s transform system. <em>ROSCon 2013</em>.</li>
<li class="">Foote, T. (2019). Python Launch Files in ROS 2. <em>ROSCon JP 2019</em>.</li>
<li class="">Gerkey, B., &amp; Konolige, K. (2010). <em>ROS: The Robot Operating System</em>. O&#x27;Reilly Media.</li>
<li class="">Grieves, M., &amp; Vickers, G. (2017). Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems. <em>Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches</em>, 85-113.</li>
<li class="">Huang, K., et al. (2022). Inner Monologue: Empowering Large Language Models to Reason about Physical Interactions. <em>arXiv preprint arXiv:2207.05697</em>.</li>
<li class="">Hussain, S. A., et al. (2020). 3D Object Detection for Autonomous Driving: A Review. <em>Sensors, 20</em>(22), 6561.</li>
<li class="">Intel. (n.d.). <em>Intel RealSense SDK Documentation</em>.</li>
<li class="">Kappler, D., et al. (2019). Real-world robot learning with deep reinforcement learning. <em>Robotics and Autonomous Systems, 120</em>, 103239.</li>
<li class="">Kirillov, A., et al. (2023). Segment Anything. <em>arXiv preprint arXiv:2304.02643</em>.</li>
<li class="">Koenig, N., &amp; O&#x27;Sullivan, J. (2014). Gazebo: Open-Source Multi-Robot Simulator. <em>IEEE International Conference on Robotics and Automation (ICRA)</em>.</li>
<li class="">Kollar, W., et al. (2018). Learning to follow language instructions in 3D environments. <em>Conference on Robot Learning (CoRL)</em>.</li>
<li class="">Kruijff, G. J. M., et al. (2012). The Gaze of the Robot: On the Role of Attention in Human-Robot Interaction. <em>ACM Transactions on Interactive Intelligent Systems, 2</em>(2), 1-28.</li>
<li class="">Kuipers, B. (2000). The spatial semantic hierarchy. <em>Artificial Intelligence, 119</em>(1-2), 191-233.</li>
<li class="">Macenski, S., et al. (2020). The ROS 2 Navigation Stack: Design Decisions and Future Work. <em>International Conference on Robotics and Automation (ICRA) Workshop</em>.</li>
<li class="">Macenski, S., et al. (2021). The ROS 2 Navigation Stack: From Birth to Fledgling. <em>Journal of Open Source Software, 6</em>(62), 3390.</li>
<li class="">Mesa, L., &amp; Rojas, A. (2020). Modern C++ and Python Programming for ROS 2. <em>Packt Publishing</em>.</li>
<li class="">Mur-Artal, R., &amp; Tardós, J. D. (2017). ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras. <em>IEEE Transactions on Robotics, 33</em>(5), 1255-1262.</li>
<li class="">National Institute of Standards and Technology. (2018). <em>Guidance for Robot Safety</em>.</li>
<li class="">NVIDIA. (n.d.). <em>NVIDIA Isaac Sim Documentation</em>.</li>
<li class="">NVIDIA. (n.d.). <em>NVIDIA Isaac Sim Documentation: ROS 2 Sensors</em>.</li>
<li class="">NVIDIA. (n.d.). <em>NVIDIA Isaac Sim Documentation: Synthetic Data Generation</em>.</li>
<li class="">NVIDIA. (n.d.). <em>NVIDIA Omniverse Documentation</em>.</li>
<li class="">NVIDIA. (n.d.). <em>Isaac ROS Visual SLAM Documentation</em>.</li>
<li class="">NVIDIA. (2023). <em>CUDA Toolkit Documentation</em>.</li>
<li class="">OpenAI. (2018). <em>Proximal Policy Optimization Algorithms</em>.</li>
<li class="">OpenAI. (n.d.). <em>Function calling and other API updates</em>.</li>
<li class="">OpenAI. (n.d.). <em>Introducing Whisper</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: Concepts</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: Launch System</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: URDF Overview</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: Writing a Python Publisher and Subscriber (rclpy)</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: Writing a Python Service and Client (rclpy)</em>.</li>
<li class="">Open Robotics. (2022). <em>ROS 2 Documentation: sensor_msgs</em>.</li>
<li class="">Open Robotics. (2022). <em>SDF Specification</em>.</li>
<li class="">Open Robotics. (n.d.). <em>Gazebo Documentation</em>.</li>
<li class="">Open Robotics. (n.d.). <em>Gazebo Documentation: Sensors</em>.</li>
<li class="">Open Robotics. (n.d.). <em>Nav2 Documentation</em>.</li>
<li class="">Pardo-Castellote, G. (2009). The OMG Data Distribution Service. <em>IEEE Computer, 42</em>(12), 105-107.</li>
<li class="">Paxton, C., et al. (2019). Rethinking Robotic Perception with Deep Learning. <em>Science Robotics, 4</em>(36), eaax2340.</li>
<li class="">Pixar Animation Studios. (n.d.). <em>Universal Scene Description (USD)</em>.</li>
<li class="">PortAudio. (n.d.). <em>PyAudio documentation</em>.</li>
<li class="">Python Software Foundation. (2023). <em>Python 3 Documentation</em>.</li>
<li class="">Quigley, M., et al. (2009). ROS: an open-source Robot Operating System. <em>OSROSE. Citeseer</em>.</li>
<li class="">Radford, A., et al. (2022). Robust Speech Recognition via Large-Scale Weak Supervision. <em>arXiv preprint arXiv:2212.04356</em>.</li>
<li class="">Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection. <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>.</li>
<li class="">ROS 2 Tutorials. (n.d.). <em>Using Parameters in Launch Files</em>.</li>
<li class="">ROS 2 Tutorials. (n.d.). <em>Using ROS 2 with Gazebo</em>.</li>
<li class="">ROS-Industrial Consortium. (n.d.). <em>ROS-Industrial Tutorials and Documentation</em>.</li>
<li class="">Rossum, B. (2012). <em>Learning ROS for Robotics Programming</em>. Packt Publishing.</li>
<li class="">Sadeghi, F., et al. (2016). Cad2rl: Real single-image flight without a single real image. <em>Robotics: Science and Systems (RSS) workshop on Learning for Manipulation</em>.</li>
<li class="">Shao, X., et al. (2020). Digital Twin for Autonomous Driving: Challenges and Opportunities. <em>IEEE Intelligent Transportation Systems Magazine, 12</em>(4), 16-29.</li>
<li class="">Siciliano, B., &amp; Khatib, O. (Eds.). (2016). <em>Springer Handbook of Robotics</em>. Springer.</li>
<li class="">Singh, R., et al. (2022). SayCan: Learning Language Grounded Robotic Skills from Natural Language Instructions. <em>Conference on Robot Learning (CoRL)</em>.</li>
<li class="">Smith, R., &amp; Chaimowicz, L. (2013). Gazebo tutorials: Understanding physics in Gazebo. <em>Open Robotics</em>.</li>
<li class="">Sutherland, I. E. (1963). SKETCHPAD: A man-machine graphical communication system. <em>Massachusetts Institute of Technology, Lincoln Laboratory</em>.</li>
<li class="">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em> (2nd ed.). MIT Press.</li>
<li class="">Svenstrup, M., &amp; Schou, C. (2018). Towards Real-time Simulation of Industrial Robots in Unity. <em>Automation 2018: Trends in Automation</em>.</li>
<li class="">Tao, F., &amp; Zhang, M. (2017). Digital Twin manufacturing shop-floor: construction and its applications. <em>Computers &amp; Industrial Engineering, 110</em>, 154-165.</li>
<li class="">Tobin, J., et al. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>.</li>
<li class="">Tremblay, J., et al. (2018). Training deep networks with synthetic data: Bridging the reality gap by domain randomization. <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>.</li>
<li class="">Toussaint, M. (2015). <em>Robot Motion Planning</em>. Springer.</li>
<li class="">Unity Technologies. (n.d.). <em>Unity Documentation: High Definition Render Pipeline</em>.</li>
<li class="">Unity Technologies. (n.d.). <em>Unity Robotics Hub Documentation</em>.</li>
<li class="">Van Rossum, G., &amp; Drake, F. L. (2009). <em>Python 3 Reference Manual</em>. CreateSpace.</li>
<li class="">Vecerik, M., et al. (2017). Successor features for transfer in reinforcement learning. <em>Advances in Neural Information Processing Systems, 30</em>.</li>
<li class="">Wang, X., et al. (2023). Voyager: An Open-Ended Embodied Agent with Large Language Models. <em>arXiv preprint arXiv:2305.16291</em>.</li>
<li class="">Wollman, D. A. (2014). <em>ROS By Example Volume 1: Hydro</em>. CreateSpace Independent Publishing Platform.</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Book-Hackathon-physical-ai-humanoid/misc/technical-plan/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Technical Plan: Physical AI &amp; Humanoid Robotics Project</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Book-Hackathon-physical-ai-humanoid/capstone/capstone-integration-guide/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">5.1 Capstone - The Integrated Humanoid Robotics System</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#goal" class="table-of-contents__link toc-highlight">Goal</a></li><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#key-concepts" class="table-of-contents__link toc-highlight">Key Concepts</a></li><li><a href="#tools-reference" class="table-of-contents__link toc-highlight">Tools (Reference)</a></li><li><a href="#chapter-sections" class="table-of-contents__link toc-highlight">Chapter Sections</a><ul><li><a href="#711-installation-guides" class="table-of-contents__link toc-highlight">7.1.1 Installation Guides</a></li><li><a href="#712-troubleshooting-common-issues" class="table-of-contents__link toc-highlight">7.1.2 Troubleshooting Common Issues</a></li><li><a href="#713-glossary-of-key-terms" class="table-of-contents__link toc-highlight">7.1.3 Glossary of Key Terms</a></li><li><a href="#714-comprehensive-references" class="table-of-contents__link toc-highlight">7.1.4 Comprehensive References</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>