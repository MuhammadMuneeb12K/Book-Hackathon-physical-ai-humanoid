"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[113],{6307:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-1/tf2-frames-transformations","title":"1.4 TF2: Frames & Transformations","description":"Building upon our understanding of URDF for describing a robot\'s physical structure, this chapter introduces TF2 \u2013 the ROS 2 framework for managing coordinate frames and transformations. In robotics, especially with complex humanoid systems, understanding where the robot is in its environment, where its sensors are relative to its body, and how its end-effectors move, all depend on accurate spatial relationships. TF2 provides a powerful, standardized way to keep track of these relationships over time.","source":"@site/docs/module-1/04-tf2-frames-transformations.mdx","sourceDirName":"module-1","slug":"/module-1/tf2-frames-transformations","permalink":"/module-1/tf2-frames-transformations","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"tf2-frames-transformations","title":"1.4 TF2: Frames & Transformations"},"sidebar":"defaultSidebar","previous":{"title":"1.3 URDF for Humanoid Robots","permalink":"/module-1/urdf-humanoid-robots"},"next":{"title":"1.5 Launch Files & Multi-node Systems","permalink":"/module-1/launch-files-multi-node"}}');var i=r(4848),t=r(8453);const a={id:"tf2-frames-transformations",title:"1.4 TF2: Frames & Transformations"},o=void 0,l={},c=[{value:"Goal",id:"goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Tools",id:"tools",level:2},{value:"Chapter Sections",id:"chapter-sections",level:2},{value:"1.4.1 The Need for Coordinate Frames in Robotics",id:"141-the-need-for-coordinate-frames-in-robotics",level:3},{value:"1.4.2 Introduction to TF2: What it Does",id:"142-introduction-to-tf2-what-it-does",level:3},{value:"1.4.3 Publishing Transforms: Static and Dynamic",id:"143-publishing-transforms-static-and-dynamic",level:3},{value:"1.4.4 Listening for Transforms and Applying Them",id:"144-listening-for-transforms-and-applying-them",level:3},{value:"1.4.5 Visualizing TF2 in RViz2",id:"145-visualizing-tf2-in-rviz2",level:3},{value:"1.4.6 Common TF2 Patterns and Pitfalls",id:"146-common-tf2-patterns-and-pitfalls",level:3},{value:"Required Diagrams",id:"required-diagrams",level:2},{value:"Hands-on Labs",id:"hands-on-labs",level:2},{value:"Lab 1.4.1: Publish a Static Transform for a Camera",id:"lab-141-publish-a-static-transform-for-a-camera",level:3},{value:"Lab 1.4.2: Listen for a Transform and Display a Point",id:"lab-142-listen-for-a-transform-and-display-a-point",level:3},{value:"Expected Output",id:"expected-output",level:2},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Real-world Applications",id:"real-world-applications",level:2},{value:"Edge Cases",id:"edge-cases",level:2},{value:"<strong>Key Entities</strong>",id:"key-entities",level:3},{value:"<strong>References</strong>",id:"references",level:3}];function d(e){const n={code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Building upon our understanding of URDF for describing a robot's physical structure, this chapter introduces TF2 \u2013 the ROS 2 framework for managing coordinate frames and transformations. In robotics, especially with complex humanoid systems, understanding where the robot is in its environment, where its sensors are relative to its body, and how its end-effectors move, all depend on accurate spatial relationships. TF2 provides a powerful, standardized way to keep track of these relationships over time."}),"\n",(0,i.jsx)(n.h2,{id:"goal",children:"Goal"}),"\n",(0,i.jsx)(n.p,{children:"The goal of this chapter is to teach students about TF2, how it manages coordinate frames and transformations, and its importance in enabling humanoid robots to reason about their own state and the location of objects and sensors in a dynamic environment."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand the concept of coordinate frames and transformations in robotics."}),"\n",(0,i.jsx)(n.li,{children:"Grasp the role and importance of TF2 in ROS 2 for managing these transformations."}),"\n",(0,i.jsx)(n.li,{children:"Learn how to publish static and dynamic transforms using TF2."}),"\n",(0,i.jsx)(n.li,{children:"Learn how to listen for and apply transforms to data from different frames."}),"\n",(0,i.jsx)(n.li,{children:"Visualize TF2 frames and their relationships in RViz2."}),"\n",(0,i.jsx)(n.li,{children:"Understand the concept of the TF2 tree and common pitfalls."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Familiarity with 3D geometry, vectors, and matrices (basic level)."}),"\n",(0,i.jsx)(n.li,{children:"Understanding of URDF and robot kinematics from the previous chapter."}),"\n",(0,i.jsx)(n.li,{children:"A functional ROS 2 Humble environment with RViz2."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Coordinate Frame:"})," A reference system used to define the position and orientation of objects in 3D space."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transformation (Transform):"})," The mathematical operation that converts coordinates from one frame to another (translation + rotation)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 (Transform Frame 2):"})," The ROS 2 package that keeps track of multiple coordinate frames and allows users to query the transformation between any two frames at any time."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 Tree:"})," The directed graph structure formed by all published transforms, where each node is a frame and each edge is a transformation."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.TransformBroadcaster"}),":"]})," A class used to publish transforms (e.g., from a sensor to the robot's base)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.Buffer"}),":"]})," Stores all received transforms."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.TransformListener"}),":"]})," Uses the ",(0,i.jsx)(n.code,{children:"Buffer"})," to query transformations."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.StaticTransformBroadcaster"}),":"]})," For publishing transforms that do not change over time."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Time Travel:"})," TF2's ability to provide transformations between any two frames at any point in time (within its buffer)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parent-Child Relationship:"})," Transforms are always defined from a child frame to a parent frame."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"tools",children:"Tools"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 Humble:"})," The robotic framework."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2:"})," The ROS 2 transformation library."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"rviz2"}),":"]})," For visualizing frames and their relationships."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_tools"}),":"]})," Command-line tools like ",(0,i.jsx)(n.code,{children:"view_frames"})," and ",(0,i.jsx)(n.code,{children:"tf2_echo"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Code Editor:"})," Visual Studio Code."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"chapter-sections",children:"Chapter Sections"}),"\n",(0,i.jsx)(n.h3,{id:"141-the-need-for-coordinate-frames-in-robotics",children:"1.4.1 The Need for Coordinate Frames in Robotics"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Why a single coordinate system is insufficient for a mobile, articulated robot."}),"\n",(0,i.jsx)(n.li,{children:"Examples: Robot base frame, camera frame, end-effector frame, world frame."}),"\n",(0,i.jsx)(n.li,{children:'The problem of knowing "where is what" relative to each other.'}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"142-introduction-to-tf2-what-it-does",children:"1.4.2 Introduction to TF2: What it Does"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Overview of TF2's core functionality:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Maintains the relationships between coordinate frames."}),"\n",(0,i.jsx)(n.li,{children:"Allows querying of transformations between any two frames."}),"\n",(0,i.jsx)(n.li,{children:'Handles "time travel" (transforms at specific past times).'}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"The TF2 Tree structure: parent-child relationships."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"143-publishing-transforms-static-and-dynamic",children:"1.4.3 Publishing Transforms: Static and Dynamic"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"StaticTransformBroadcaster"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"When to use static transforms (e.g., sensor mounted rigidly on a robot link)."}),"\n",(0,i.jsx)(n.li,{children:"Python example of publishing a static transform."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"TransformBroadcaster"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"When to use dynamic transforms (e.g., robot's odometry, moving object detections)."}),"\n",(0,i.jsx)(n.li,{children:"Python example of publishing a dynamic transform from an odometry source."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"144-listening-for-transforms-and-applying-them",children:"1.4.4 Listening for Transforms and Applying Them"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"Buffer"})," and ",(0,i.jsx)(n.code,{children:"TransformListener"}),":"]})," How to set up a listener."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Querying Transforms:"})," ",(0,i.jsx)(n.code,{children:"tf2_buffer.lookup_transform(target_frame, source_frame, time)"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Applying Transforms:"})," Transforming points, vectors, and poses from one frame to another."]}),"\n",(0,i.jsx)(n.li,{children:"Python example: Transforming a detected object's position from camera frame to robot base frame."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"145-visualizing-tf2-in-rviz2",children:"1.4.5 Visualizing TF2 in RViz2"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Adding the TF Display:"})," Observing the TF2 tree and individual frames."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_echo"}),":"]})," Command-line tool to inspect the transform between two frames."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"view_frames"}),":"]})," Generating a PDF visualization of the entire TF2 tree."]}),"\n",(0,i.jsx)(n.li,{children:"Debugging TF2 issues using RViz2."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"146-common-tf2-patterns-and-pitfalls",children:"1.4.6 Common TF2 Patterns and Pitfalls"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Establishing a World Frame:"})," ",(0,i.jsx)(n.code,{children:"map"}),", ",(0,i.jsx)(n.code,{children:"odom"}),", or ",(0,i.jsx)(n.code,{children:"world"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["The Importance of ",(0,i.jsx)(n.code,{children:"base_link"}),":"]})," The robot's primary reference frame."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transforming Sensor Data:"})," Correctly relating sensor measurements to the robot's state."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Loop Closures:"})," Avoiding cycles in the TF2 tree."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stale Transforms:"})," What happens when transforms are not updated frequently enough."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"required-diagrams",children:"Required Diagrams"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 Tree Structure (Humanoid Example):"})," Illustrating a hierarchy like ",(0,i.jsx)(n.code,{children:"map -> odom -> base_link -> torso_link -> head_link -> camera_link"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transformation Illustration:"})," A 2D or 3D drawing showing a point in one frame being transformed into another frame."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 Publisher/Listener Flow:"})," A diagram showing a node publishing transforms, TF2 storing them, and another node querying them."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"hands-on-labs",children:"Hands-on Labs"}),"\n",(0,i.jsx)(n.h3,{id:"lab-141-publish-a-static-transform-for-a-camera",children:"Lab 1.4.1: Publish a Static Transform for a Camera"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Objective:"})," Publish a static transform for a simulated camera mounted on the head of the humanoid robot from the previous lab."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Prerequisites:"})," Completed Lab 1.3.1 (URDF visualization)."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Instructions:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["Create a new ROS 2 Python package (or add to ",(0,i.jsx)(n.code,{children:"my_humanoid_description"})," if preferred):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd <your_ros2_ws>/src\r\nros2 pkg create --build-type ament_python static_tf_publisher --dependencies rclpy tf2_ros geometry_msgs\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigate into the package and create the script:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd static_tf_publisher/static_tf_publisher\r\ntouch static_camera_tf_publisher.py\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["Edit ",(0,i.jsx)(n.code,{children:"static_camera_tf_publisher.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom tf2_ros.static_transform_broadcaster import StaticTransformBroadcaster\r\nfrom geometry_msgs.msg import TransformStamped\r\nimport math\r\n\r\nclass StaticCameraTFBroadcaster(Node):\r\n\r\n    def __init__(self):\r\n        super().__init__('static_camera_tf_broadcaster')\r\n        self.tf_static_broadcaster = StaticTransformBroadcaster(self)\r\n        self.declare_parameters(\r\n            namespace='',\r\n            parameters=[\r\n                ('x', 0.0), ('y', 0.0), ('z', 0.0),\r\n                ('roll', 0.0), ('pitch', 0.0), ('yaw', 0.0),\r\n                ('frame_id', 'head_link'),\r\n                ('child_frame_id', 'camera_link')\r\n            ]\r\n        )\r\n        self.publish_static_tf()\r\n        self.get_logger().info('Static Camera TF Broadcaster Node started.')\r\n\r\n    def publish_static_tf(self):\r\n        t = TransformStamped()\r\n\r\n        t.header.stamp = self.get_clock().now().to_msg()\r\n        t.header.frame_id = self.get_parameter('frame_id').get_parameter_value().string_value\r\n        t.child_frame_id = self.get_parameter('child_frame_id').get_parameter_value().string_value\r\n\r\n        t.transform.translation.x = self.get_parameter('x').get_parameter_value().double_value\r\n        t.transform.translation.y = self.get_parameter('y').get_parameter_value().double_value\r\n        t.transform.translation.z = self.get_parameter('z').get_parameter_value().double_value\r\n\r\n        # Convert Euler angles (roll, pitch, yaw) to quaternion\r\n        roll = self.get_parameter('roll').get_parameter_value().double_value\r\n        pitch = self.get_parameter('pitch').get_parameter_value().double_value\r\n        yaw = self.get_parameter('yaw').get_parameter_value().double_value\r\n\r\n        cy = math.cos(yaw * 0.5)\r\n        sy = math.sin(yaw * 0.5)\r\n        cp = math.cos(pitch * 0.5)\r\n        sp = math.sin(pitch * 0.5)\r\n        cr = math.cos(roll * 0.5)\r\n        sr = math.sin(roll * 0.5)\r\n\r\n        t.transform.rotation.w = cr * cp * cy + sr * sp * sy\r\n        t.transform.rotation.x = sr * cp * cy - cr * sp * sy\r\n        t.transform.rotation.y = cr * sp * cy + sr * cp * sy\r\n        t.transform.rotation.z = cr * cp * sy - sr * sp * cy\r\n\r\n        self.tf_static_broadcaster.sendTransform(t)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = StaticCameraTFBroadcaster()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["Edit ",(0,i.jsx)(n.code,{children:"setup.py"})," for ",(0,i.jsx)(n.code,{children:"static_tf_publisher"}),":"]})," Add the entry point.","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from setuptools import find_packages, setup\r\n\r\npackage_name = 'static_tf_publisher'\r\n\r\nsetup(\r\n    name=package_name,\r\n    version='0.0.0',\r\n    packages=find_packages(exclude=['test']),\r\n    data_files=[\r\n        ('share/' + package_name, ['package.xml']),\r\n    ],\r\n    install_requires=['setuptools'],\r\n    zip_safe=True,\r\n    maintainer='your_name',\r\n    maintainer_email='your_email@example.com',\r\n    description='ROS 2 package for publishing static TF2 transforms.',\r\n    license='Apache-2.0',\r\n    tests_require=['pytest'],\r\n    entry_points={\r\n        'console_scripts': [\r\n            'static_camera_tf_publisher = static_tf_publisher.static_camera_tf_publisher:main',\r\n        ],\r\n    },\r\n)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Build your package and source your workspace:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd <your_ros2_ws>\r\ncolcon build --packages-select static_tf_publisher\r\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Run the URDF display launch file from Lab 1.3.1 in one terminal:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_humanoid_description display_humanoid.launch.py\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"In a separate terminal, run the static TF publisher:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run static_tf_publisher static_camera_tf_publisher --ros-args -p x:=0.1 -p z:=0.05 -p frame_id:=head_link -p child_frame_id:=camera_link\n"})}),"\n",(0,i.jsxs)(n.em,{children:["This command will mount a ",(0,i.jsx)(n.code,{children:"camera_link"})," 0.1m forward and 0.05m up from ",(0,i.jsx)(n.code,{children:"head_link"}),"."]})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:'In RViz2, add a "TF" display.'})," You should now see the ",(0,i.jsx)(n.code,{children:"head_link"})," and ",(0,i.jsx)(n.code,{children:"camera_link"})," frames, with ",(0,i.jsx)(n.code,{children:"camera_link"})," offset from ",(0,i.jsx)(n.code,{children:"head_link"}),". You can also use ",(0,i.jsx)(n.code,{children:"tf2_echo head_link camera_link"})," in a terminal to see the transform."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"lab-142-listen-for-a-transform-and-display-a-point",children:"Lab 1.4.2: Listen for a Transform and Display a Point"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Objective:"})," Create a node that listens for the transform between ",(0,i.jsx)(n.code,{children:"base_link"})," and ",(0,i.jsx)(n.code,{children:"camera_link"})," and transforms a fixed point from ",(0,i.jsx)(n.code,{children:"camera_link"})," to ",(0,i.jsx)(n.code,{children:"base_link"}),", then publishes it as a ",(0,i.jsx)(n.code,{children:"geometry_msgs/msg/PointStamped"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Prerequisites:"})," Completed Lab 1.4.1."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Instructions:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["In the ",(0,i.jsx)(n.code,{children:"static_tf_publisher"})," package, create ",(0,i.jsx)(n.code,{children:"point_transformer.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom tf2_ros import Buffer, TransformListener\r\nfrom geometry_msgs.msg import PointStamped, TransformStamped\r\nimport tf2_geometry_msgs  # Import to use transform_point function\r\n\r\nclass PointTransformer(Node):\r\n\r\n    def __init__(self):\r\n        super().__init__('point_transformer')\r\n        self.tf_buffer = Buffer()\r\n        self.tf_listener = TransformListener(self.tf_buffer, self)\r\n        self.point_publisher = self.create_publisher(PointStamped, '/transformed_point', 10)\r\n        self.timer = self.create_timer(1.0, self.on_timer) # Check for transform every 1 second\r\n        self.get_logger().info('Point Transformer Node started.')\r\n\r\n    def on_timer(self):\r\n        # Define a point in the camera_link frame (e.g., 1m directly in front of the camera)\r\n        point_in_camera_frame = PointStamped()\r\n        point_in_camera_frame.header.frame_id = 'camera_link'\r\n        point_in_camera_frame.header.stamp = self.get_clock().now().to_msg()\r\n        point_in_camera_frame.point.x = 1.0\r\n        point_in_camera_frame.point.y = 0.0\r\n        point_in_camera_frame.point.z = 0.0\r\n\r\n        target_frame = 'base_link'\r\n        source_frame = 'camera_link'\r\n\r\n        try:\r\n            # Get the transform from source_frame to target_frame\r\n            transform = self.tf_buffer.lookup_transform(\r\n                target_frame,\r\n                source_frame,\r\n                rclpy.time.Time() # Get the latest available transform\r\n            )\r\n\r\n            # Transform the point\r\n            point_in_base_frame = tf2_geometry_msgs.do_transform_point(point_in_camera_frame, transform)\r\n            self.get_logger().info(\r\n                f'Point in {source_frame} ({point_in_camera_frame.point.x:.2f}, {point_in_camera_frame.point.y:.2f}, {point_in_camera_frame.point.z:.2f}) '\r\n                f'transformed to {target_frame} ({point_in_base_frame.point.x:.2f}, {point_in_base_frame.point.y:.2f}, {point_in_base_frame.point.z:.2f})'\r\n            )\r\n            self.point_publisher.publish(point_in_base_frame)\r\n\r\n        except Exception as ex:\r\n            self.get_logger().warn(f'Could not transform point from {source_frame} to {target_frame}: {ex}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = PointTransformer()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["Edit ",(0,i.jsx)(n.code,{children:"setup.py"})," for ",(0,i.jsx)(n.code,{children:"static_tf_publisher"}),":"]})," Add the entry point.","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# ... (previous setup.py content) ...\r\n    entry_points={\r\n        'console_scripts': [\r\n            'static_camera_tf_publisher = static_tf_publisher.static_camera_tf_publisher:main',\r\n            'point_transformer = static_tf_publisher.point_transformer:main', # Add this line\r\n        ],\r\n    },\r\n)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Build your package and source your workspace:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd <your_ros2_ws>\r\ncolcon build --packages-select static_tf_publisher\r\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Ensure Lab 1.3.1 launch file and Lab 1.4.1 static TF publisher are running."})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"In a separate terminal, run the point transformer:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run static_tf_publisher point_transformer\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"In RViz2:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:'Add a "PointStamped" display.'}),"\n",(0,i.jsxs)(n.li,{children:["Set its Topic to ",(0,i.jsx)(n.code,{children:"/transformed_point"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Observe the fixed point (originally 1m in front of the camera) displayed in the ",(0,i.jsx)(n.code,{children:"base_link"})," frame. As you manipulate the ",(0,i.jsx)(n.code,{children:"head_yaw_joint"})," in ",(0,i.jsx)(n.code,{children:"joint_state_publisher_gui"}),", the ",(0,i.jsx)(n.code,{children:"camera_link"})," (and thus the point) should move relative to ",(0,i.jsx)(n.code,{children:"base_link"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"expected-output",children:"Expected Output"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A clear understanding of how TF2 organizes spatial relationships."}),"\n",(0,i.jsx)(n.li,{children:"Ability to publish static transforms for rigidly mounted components."}),"\n",(0,i.jsx)(n.li,{children:"Ability to listen for transforms between arbitrary frames."}),"\n",(0,i.jsx)(n.li,{children:"Ability to transform geometric data (e.g., points, poses) from one frame to another."}),"\n",(0,i.jsx)(n.li,{children:"Visualization of coordinate frames and transformed points in RViz2."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:'Why is TF2 often referred to as providing "time travel" capabilities, and what does this mean in practice for robotics applications?'}),"\n",(0,i.jsxs)(n.li,{children:["Describe a scenario where a ",(0,i.jsx)(n.code,{children:"StaticTransformBroadcaster"})," would be more appropriate than a regular ",(0,i.jsx)(n.code,{children:"TransformBroadcaster"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["You have a sensor reporting a point in ",(0,i.jsx)(n.code,{children:"sensor_frame"}),". How would you use TF2 to find this point's coordinates in the ",(0,i.jsx)(n.code,{children:"world"})," frame? Outline the steps."]}),"\n",(0,i.jsxs)(n.li,{children:["What happens if you try to ",(0,i.jsx)(n.code,{children:"lookup_transform"})," between two frames that are not connected in the TF2 tree?"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"real-world-applications",children:"Real-world Applications"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robot Navigation:"})," Transforming sensor data (LiDAR scans, camera detections) from sensor frames into the robot's ",(0,i.jsx)(n.code,{children:"base_link"})," or ",(0,i.jsx)(n.code,{children:"odom"})," frame for mapping and localization."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Humanoid Body Tracking:"})," Relating the position of human body parts (e.g., detected by a depth camera) to the humanoid robot's end-effector for interaction."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Manipulator Control:"})," Calculating the required end-effector pose in the ",(0,i.jsx)(n.code,{children:"base_link"})," frame and then transforming it to individual joint commands using inverse kinematics."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multi-robot Coordination:"})," Allowing robots to understand each other's positions and orientations in a common ",(0,i.jsx)(n.code,{children:"map"})," frame."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"edge-cases",children:"Edge Cases"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transform Not Available:"})," If a requested transform is not published or the TF2 buffer is not up-to-date, ",(0,i.jsx)(n.code,{children:"lookup_transform"})," will throw an exception (",(0,i.jsx)(n.code,{children:"tf2_ros.TransformException"}),")."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 Tree Loops:"})," Incorrectly defined transforms can create cycles in the TF2 tree, leading to errors and making transformations impossible."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Time Synchronization Issues:"})," Poor time synchronization between different nodes publishing transforms can lead to inaccurate or inconsistent transformations."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Large Number of Frames:"})," A very complex TF2 tree with many frames can consume significant memory and processing power, especially if transforms are published at high rates."]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"key-entities",children:(0,i.jsx)(n.strong,{children:"Key Entities"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TF2 (Transform Frame 2):"})," A ROS 2 library for maintaining and querying the relationship between multiple coordinate frames over time."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Coordinate Frame:"})," A 3D reference system used to specify positions and orientations. In TF2, frames are organized in a tree structure."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transform:"})," A mathematical description (translation and rotation) that converts coordinates from one frame to another."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.TransformBroadcaster"}),":"]})," A Python class for publishing dynamic (time-varying) transforms on the ",(0,i.jsx)(n.code,{children:"/tf"})," topic."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.StaticTransformBroadcaster"}),":"]})," A Python class for publishing static (time-invariant) transforms on the ",(0,i.jsx)(n.code,{children:"/tf_static"})," topic."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.Buffer"}),":"]}),' An internal data structure in TF2 that stores all received transforms, allowing for efficient lookup and "time travel."']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"tf2_ros.TransformListener"}),":"]})," A Python class that populates the ",(0,i.jsx)(n.code,{children:"tf2_ros.Buffer"})," by subscribing to ",(0,i.jsx)(n.code,{children:"/tf"})," and ",(0,i.jsx)(n.code,{children:"/tf_static"})," topics."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"geometry_msgs.msg.TransformStamped"}),":"]})," A ROS 2 message type used to represent a single transform, including its timestamp, parent frame ID (",(0,i.jsx)(n.code,{children:"header.frame_id"}),"), child frame ID (",(0,i.jsx)(n.code,{children:"child_frame_id"}),"), and the translation/rotation components."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:[(0,i.jsx)(n.code,{children:"geometry_msgs.msg.PointStamped"}),":"]})," A ROS 2 message type representing a 3D point along with its associated coordinate frame and timestamp."]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"references",children:(0,i.jsx)(n.strong,{children:"References"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,i.jsx)(n.em,{children:"ROS 2 Documentation: TF2 Tutorials"}),". (Placeholder citation)"]}),"\n",(0,i.jsxs)(n.li,{children:["Foote, T. (2013). tf2: The next generation of ROS's transform system. ",(0,i.jsx)(n.em,{children:"ROSCon 2013"}),". (Placeholder citation)"]}),"\n",(0,i.jsxs)(n.li,{children:["Quigley, M., et al. (2009). ROS: an open-source Robot Operating System. ",(0,i.jsx)(n.em,{children:"OSROSE. Citeseer"}),". (Placeholder citation)"]}),"\n",(0,i.jsxs)(n.li,{children:["Siciliano, B., & Khatib, O. (Eds.). (2016). ",(0,i.jsx)(n.em,{children:"Springer Handbook of Robotics"}),". Springer. (Placeholder citation)"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var s=r(6540);const i={},t=s.createContext(i);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);