"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[285],{1812:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"appendices/appendices","title":"7.1 Appendices - Resources and Further Reading","description":"The Appendices serve as a comprehensive resource, consolidating crucial supplementary information that enhances the reader\'s understanding and practical application of the concepts covered in this book. This section provides detailed installation guides, common troubleshooting tips, a glossary of key terms, and a comprehensive list of academic and technical references, all formatted according to APA style.","source":"@site/docs/appendices/index.mdx","sourceDirName":"appendices","slug":"/appendices/","permalink":"/appendices/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"appendices","title":"7.1 Appendices - Resources and Further Reading"},"sidebar":"defaultSidebar","previous":{"title":"Technical Plan: Physical AI & Humanoid Robotics Project","permalink":"/misc/technical-plan"},"next":{"title":"5.1 Capstone - The Integrated Humanoid Robotics System","permalink":"/capstone/capstone-integration-guide"}}');var r=i(4848),o=i(8453);const l={id:"appendices",title:"7.1 Appendices - Resources and Further Reading"},t=void 0,a={},c=[{value:"Goal",id:"goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Tools (Reference)",id:"tools-reference",level:2},{value:"Chapter Sections",id:"chapter-sections",level:2},{value:"7.1.1 Installation Guides",id:"711-installation-guides",level:3},{value:"7.1.2 Troubleshooting Common Issues",id:"712-troubleshooting-common-issues",level:3},{value:"7.1.3 Glossary of Key Terms",id:"713-glossary-of-key-terms",level:3},{value:"7.1.4 Comprehensive References",id:"714-comprehensive-references",level:3}];function d(e){const n={code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"The Appendices serve as a comprehensive resource, consolidating crucial supplementary information that enhances the reader's understanding and practical application of the concepts covered in this book. This section provides detailed installation guides, common troubleshooting tips, a glossary of key terms, and a comprehensive list of academic and technical references, all formatted according to APA style."}),"\n",(0,r.jsx)(n.h2,{id:"goal",children:"Goal"}),"\n",(0,r.jsx)(n.p,{children:"To provide readily accessible supplementary information, practical guides, and comprehensive references to support the reader's journey in physical AI and humanoid robotics, facilitating further exploration and problem-solving."}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Access detailed installation instructions for core software components."}),"\n",(0,r.jsx)(n.li,{children:"Utilize troubleshooting guides to diagnose and resolve common issues."}),"\n",(0,r.jsx)(n.li,{children:"Understand specialized terminology through a comprehensive glossary."}),"\n",(0,r.jsx)(n.li,{children:"Explore additional academic and technical resources through APA-formatted references."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A desire to delve deeper into the technical details and resolve practical challenges."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Documentation:"})," Organized, accessible information for reference."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Best Practices:"})," Recommended methods for optimal results."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Troubleshooting:"})," Systematic approach to problem diagnosis and resolution."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Glossary:"})," A collection of specialized terms and their definitions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Academic Citation:"})," A standardized way of referencing sources."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"tools-reference",children:"Tools (Reference)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Operating Systems:"})," Ubuntu 22.04 LTS"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Distribution:"})," Humble Hawksbill"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simulation Environments:"})," Gazebo (Ignition Fortress), NVIDIA Isaac Sim, Unity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Programming Languages:"})," Python, C++"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Version Control:"})," Git"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"chapter-sections",children:"Chapter Sections"}),"\n",(0,r.jsx)(n.h3,{id:"711-installation-guides",children:"7.1.1 Installation Guides"}),"\n",(0,r.jsx)(n.p,{children:'This section provides detailed, step-by-step instructions for installing and configuring the primary software components used throughout this book. While initial setup was covered in the "Getting Started" chapter, this appendix offers more in-depth guidance and addresses potential system-specific nuances.'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.1 ROS 2 Humble Hawksbill (Detailed)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Full installation from Debian packages."}),"\n",(0,r.jsx)(n.li,{children:"Building from source (for advanced users or specific development needs)."}),"\n",(0,r.jsx)(n.li,{children:"Setting up environment variables permanently."}),"\n",(0,r.jsx)(n.li,{children:"Troubleshooting common installation issues."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.2 Gazebo (Ignition Fortress)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Installation via ",(0,r.jsx)(n.code,{children:"apt"})," (with ROS 2 integration)."]}),"\n",(0,r.jsx)(n.li,{children:"Verifying installation and dependencies."}),"\n",(0,r.jsx)(n.li,{children:"Troubleshooting: graphical errors, missing models."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.3 NVIDIA Isaac Sim"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Prerequisites: NVIDIA GPU drivers, CUDA Toolkit, Omniverse Launcher."}),"\n",(0,r.jsx)(n.li,{children:"Step-by-step installation via Omniverse Launcher."}),"\n",(0,r.jsx)(n.li,{children:"Common issues: connection errors, GPU memory."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.4 Unity Editor for Robotics"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Installing Unity Hub and Unity Editor (LTS version recommended)."}),"\n",(0,r.jsx)(n.li,{children:"Adding HDRP and Unity Robotics Hub packages."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.5 Python Environment Management"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Advanced ",(0,r.jsx)(n.code,{children:"venv"})," usage."]}),"\n",(0,r.jsxs)(n.li,{children:["Using ",(0,r.jsx)(n.code,{children:"conda"})," for isolated environments."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.1.6 Essential Development Tools"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Visual Studio Code setup with recommended extensions."}),"\n",(0,r.jsx)(n.li,{children:"Git configuration and best practices."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"712-troubleshooting-common-issues",children:"7.1.2 Troubleshooting Common Issues"}),"\n",(0,r.jsx)(n.p,{children:"This section addresses frequently encountered problems during development, simulation, and hardware interaction, providing systematic solutions."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.2.1 ROS 2 Communication Issues"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Nodes not discovering each other (network configuration, ",(0,r.jsx)(n.code,{children:"ROS_DOMAIN_ID"}),")."]}),"\n",(0,r.jsx)(n.li,{children:"Message type mismatches."}),"\n",(0,r.jsx)(n.li,{children:"QoS policy conflicts."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.2.2 Simulation Environment Problems"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Gazebo: Unstable physics, models not loading, graphical glitches."}),"\n",(0,r.jsx)(n.li,{children:"Isaac Sim: Performance issues, USD asset loading errors, GPU driver conflicts."}),"\n",(0,r.jsx)(n.li,{children:"Unity: Rendering artifacts, model import failures."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.2.3 AI/ML Model Deployment Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"CUDA/cuDNN compatibility issues."}),"\n",(0,r.jsx)(n.li,{children:"TensorRT optimization errors."}),"\n",(0,r.jsx)(n.li,{children:"Model inference latency."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.2.4 TF2 and Coordinate Frame Errors"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Frames not published, ",(0,r.jsx)(n.code,{children:"lookup_transform"})," exceptions."]}),"\n",(0,r.jsx)(n.li,{children:"TF2 tree loops."}),"\n",(0,r.jsx)(n.li,{children:"Time synchronization problems."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"7.1.2.5 Hardware Interaction Issues"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sensor driver failures."}),"\n",(0,r.jsx)(n.li,{children:"Actuator control errors."}),"\n",(0,r.jsx)(n.li,{children:"Network connectivity to robot."}),"\n",(0,r.jsx)(n.li,{children:"E-Stop malfunctions."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"713-glossary-of-key-terms",children:"7.1.3 Glossary of Key Terms"}),"\n",(0,r.jsx)(n.p,{children:"This glossary provides definitions for technical terms and acronyms used throughout the book, serving as a quick reference guide."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Action Primitive:"})," A fundamental, low-level robotic action that can be executed directly by the robot's control system (e.g., ",(0,r.jsx)(n.code,{children:"navigate_to(location)"}),", ",(0,r.jsx)(n.code,{children:"grasp_object(object_id)"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AMCL (Adaptive Monte Carlo Localization):"})," A probabilistic localization algorithm for 2D mobile robots."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ASR (Automatic Speech Recognition):"})," Technology converting spoken language into text."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Colcon:"})," The build system used for ROS 2 packages."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Costmap:"})," A grid-based map representation used in Nav2, indicating the cost of traversing each cell."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CUDA:"})," NVIDIA's parallel computing platform and API model for GPUs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"cuDNN:"})," NVIDIA CUDA Deep Neural Network library, a GPU-accelerated library of primitives for deep learning."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"DDS (Data Distribution Service):"})," The middleware standard that ROS 2 uses for real-time, peer-to-peer communication."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Digital Twin:"})," A virtual replica of a physical system, continuously updated with real-time data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain Randomization:"})," Randomizing non-essential simulation parameters to improve sim-to-real transfer."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"E-Stop (Emergency Stop):"})," A safety mechanism to immediately halt robot operation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gazebo:"})," A powerful 3D robot simulator."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"HDRP (High Definition Render Pipeline):"})," Unity's advanced rendering solution for high-fidelity graphics."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"HRI (Human-Robot Interaction):"})," The study of how humans and robots interact."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IMU (Inertial Measurement Unit):"})," Sensor measuring orientation, angular velocity, and linear acceleration."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS GEMs:"})," NVIDIA's hardware-accelerated packages for ROS 2."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim:"})," NVIDIA's GPU-accelerated robotics simulation platform on Omniverse."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Jetson:"})," NVIDIA's family of embedded computing boards for AI at the edge."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM (Large Language Model):"})," AI model for understanding and generating human language."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localization:"})," Determining the robot's precise position and orientation in an environment."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loop Closure:"})," A SLAM process recognizing previously visited locations to correct map errors."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Nav2:"})," The ROS 2 Navigation Stack."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"NLP (Natural Language Processing):"})," AI field dealing with human language."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Node:"})," An executable process in ROS 2."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object Grounding:"})," Linking linguistic descriptions to physical entities in sensory data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Omniverse:"})," NVIDIA's platform for 3D workflows and simulation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Policy (Robotic):"})," A function mapping robot states to actions, often learned via RL."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt Engineering:"})," Crafting effective inputs for LLMs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"QoS (Quality of Service):"})," Settings in DDS defining data transfer behavior."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"rclpy:"})," The Python client library for ROS 2."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reinforcement Learning (RL):"})," ML paradigm where an agent learns through reward/penalty."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 (Robot Operating System 2):"})," Open-source framework for robot software development."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RViz2:"})," ROS 2's 3D visualization tool."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SDF (Simulation Description Format):"})," XML format for Gazebo models and worlds."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real Transfer:"})," Transferring AI models/policies from simulation to real hardware."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping):"})," Building a map while tracking location within it."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Data Generation (SDG):"})," Creating artificial data from simulations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TF2 (Transform Frame 2):"})," ROS 2 system for managing coordinate frames and transformations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Topic:"})," ROS 2 communication channel (publish-subscribe)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"URDF (Unified Robot Description Format):"})," XML format for describing robot kinematics and visual properties."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"USD (Universal Scene Description):"})," Pixar's open-source 3D scene description format."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VAD (Voice Activity Detection):"})," Detecting presence of speech in audio."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VLA (Vision-Language-Action):"})," Integrated paradigm where robots use vision, language, and planning for action."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VSLAM (Visual SLAM):"})," SLAM using visual sensor data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Whisper:"})," OpenAI's ASR model."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Xacro:"})," XML macro language for modular URDF."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"YOLO (You Only Look Once):"})," Real-time object detection model."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"714-comprehensive-references",children:"7.1.4 Comprehensive References"}),"\n",(0,r.jsx)(n.p,{children:"This section lists all academic papers, books, and online resources cited or referenced throughout this book, organized alphabetically by the first author's last name. (Note: Placeholder citations are used throughout the book; this section would contain their full, properly formatted entries.)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Arkin, R. C. (1998). ",(0,r.jsx)(n.em,{children:"Behavior-Based Robotics"}),". MIT Press."]}),"\n",(0,r.jsxs)(n.li,{children:["Billard, A., & Kragic, D. (2019). Trends in robot learning and interaction. ",(0,r.jsx)(n.em,{children:"Science Robotics, 4"}),"(27), eaav8572."]}),"\n",(0,r.jsxs)(n.li,{children:["Boiko, S., et al. (2020). Isaac Gym: High Performance GPU-based Physics Simulation for Robot Learning. ",(0,r.jsx)(n.em,{children:"arXiv preprint arXiv:2009.11728"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Brooks, R. A. (1991). Intelligence without representation. ",(0,r.jsx)(n.em,{children:"Artificial Intelligence, 47"}),"(1-3), 139-159."]}),"\n",(0,r.jsxs)(n.li,{children:["Cadena, C., et al. (2016). Past, present, and future of simultaneous localization and mapping: Toward the new era of semantic SLAM. ",(0,r.jsx)(n.em,{children:"IEEE Transactions on Robotics, 32"}),"(6), 1309-1332."]}),"\n",(0,r.jsxs)(n.li,{children:["Canonical. (2022). ",(0,r.jsx)(n.em,{children:"Ubuntu 22.04 LTS (Jammy Jellyfish) Release Notes"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Davison, A. J., et al. (2007). MonoSLAM: Real-time single camera SLAM. ",(0,r.jsx)(n.em,{children:"IEEE Transactions on Pattern Analysis and Machine Intelligence, 29"}),"(6), 1052-1067."]}),"\n",(0,r.jsxs)(n.li,{children:["Dhar, P., et al. (2021). A Survey on Speech Recognition for Robotics. ",(0,r.jsx)(n.em,{children:"Sensors, 21"}),"(14), 4811."]}),"\n",(0,r.jsxs)(n.li,{children:["Erchov, S. (2018). ",(0,r.jsx)(n.em,{children:"Mastering ROS for Robotics Programming"}),". Packt Publishing."]}),"\n",(0,r.jsxs)(n.li,{children:["Feil-Seifer, D., & Mataric, M. J. (2011). Towards a taxonomy of robot failures: Analyzing types of failure in HRI. ",(0,r.jsx)(n.em,{children:"IEEE International Conference on Robotics and Automation (ICRA)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Foote, T. (2013). tf2: The next generation of ROS's transform system. ",(0,r.jsx)(n.em,{children:"ROSCon 2013"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Foote, T. (2019). Python Launch Files in ROS 2. ",(0,r.jsx)(n.em,{children:"ROSCon JP 2019"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Gerkey, B., & Konolige, K. (2010). ",(0,r.jsx)(n.em,{children:"ROS: The Robot Operating System"}),". O'Reilly Media."]}),"\n",(0,r.jsxs)(n.li,{children:["Grieves, M., & Vickers, G. (2017). Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems. ",(0,r.jsx)(n.em,{children:"Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches"}),", 85-113."]}),"\n",(0,r.jsxs)(n.li,{children:["Huang, K., et al. (2022). Inner Monologue: Empowering Large Language Models to Reason about Physical Interactions. ",(0,r.jsx)(n.em,{children:"arXiv preprint arXiv:2207.05697"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Hussain, S. A., et al. (2020). 3D Object Detection for Autonomous Driving: A Review. ",(0,r.jsx)(n.em,{children:"Sensors, 20"}),"(22), 6561."]}),"\n",(0,r.jsxs)(n.li,{children:["Intel. (n.d.). ",(0,r.jsx)(n.em,{children:"Intel RealSense SDK Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Kappler, D., et al. (2019). Real-world robot learning with deep reinforcement learning. ",(0,r.jsx)(n.em,{children:"Robotics and Autonomous Systems, 120"}),", 103239."]}),"\n",(0,r.jsxs)(n.li,{children:["Kirillov, A., et al. (2023). Segment Anything. ",(0,r.jsx)(n.em,{children:"arXiv preprint arXiv:2304.02643"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Koenig, N., & O'Sullivan, J. (2014). Gazebo: Open-Source Multi-Robot Simulator. ",(0,r.jsx)(n.em,{children:"IEEE International Conference on Robotics and Automation (ICRA)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Kollar, W., et al. (2018). Learning to follow language instructions in 3D environments. ",(0,r.jsx)(n.em,{children:"Conference on Robot Learning (CoRL)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Kruijff, G. J. M., et al. (2012). The Gaze of the Robot: On the Role of Attention in Human-Robot Interaction. ",(0,r.jsx)(n.em,{children:"ACM Transactions on Interactive Intelligent Systems, 2"}),"(2), 1-28."]}),"\n",(0,r.jsxs)(n.li,{children:["Kuipers, B. (2000). The spatial semantic hierarchy. ",(0,r.jsx)(n.em,{children:"Artificial Intelligence, 119"}),"(1-2), 191-233."]}),"\n",(0,r.jsxs)(n.li,{children:["Macenski, S., et al. (2020). The ROS 2 Navigation Stack: Design Decisions and Future Work. ",(0,r.jsx)(n.em,{children:"International Conference on Robotics and Automation (ICRA) Workshop"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Macenski, S., et al. (2021). The ROS 2 Navigation Stack: From Birth to Fledgling. ",(0,r.jsx)(n.em,{children:"Journal of Open Source Software, 6"}),"(62), 3390."]}),"\n",(0,r.jsxs)(n.li,{children:["Mesa, L., & Rojas, A. (2020). Modern C++ and Python Programming for ROS 2. ",(0,r.jsx)(n.em,{children:"Packt Publishing"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Mur-Artal, R., & Tard\xf3s, J. D. (2017). ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras. ",(0,r.jsx)(n.em,{children:"IEEE Transactions on Robotics, 33"}),"(5), 1255-1262."]}),"\n",(0,r.jsxs)(n.li,{children:["National Institute of Standards and Technology. (2018). ",(0,r.jsx)(n.em,{children:"Guidance for Robot Safety"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (n.d.). ",(0,r.jsx)(n.em,{children:"NVIDIA Isaac Sim Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (n.d.). ",(0,r.jsx)(n.em,{children:"NVIDIA Isaac Sim Documentation: ROS 2 Sensors"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (n.d.). ",(0,r.jsx)(n.em,{children:"NVIDIA Isaac Sim Documentation: Synthetic Data Generation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (n.d.). ",(0,r.jsx)(n.em,{children:"NVIDIA Omniverse Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (n.d.). ",(0,r.jsx)(n.em,{children:"Isaac ROS Visual SLAM Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["NVIDIA. (2023). ",(0,r.jsx)(n.em,{children:"CUDA Toolkit Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["OpenAI. (2018). ",(0,r.jsx)(n.em,{children:"Proximal Policy Optimization Algorithms"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["OpenAI. (n.d.). ",(0,r.jsx)(n.em,{children:"Function calling and other API updates"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["OpenAI. (n.d.). ",(0,r.jsx)(n.em,{children:"Introducing Whisper"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: Concepts"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: Launch System"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: URDF Overview"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: Writing a Python Publisher and Subscriber (rclpy)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: Writing a Python Service and Client (rclpy)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"ROS 2 Documentation: sensor_msgs"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (2022). ",(0,r.jsx)(n.em,{children:"SDF Specification"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (n.d.). ",(0,r.jsx)(n.em,{children:"Gazebo Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (n.d.). ",(0,r.jsx)(n.em,{children:"Gazebo Documentation: Sensors"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Open Robotics. (n.d.). ",(0,r.jsx)(n.em,{children:"Nav2 Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Pardo-Castellote, G. (2009). The OMG Data Distribution Service. ",(0,r.jsx)(n.em,{children:"IEEE Computer, 42"}),"(12), 105-107."]}),"\n",(0,r.jsxs)(n.li,{children:["Paxton, C., et al. (2019). Rethinking Robotic Perception with Deep Learning. ",(0,r.jsx)(n.em,{children:"Science Robotics, 4"}),"(36), eaax2340."]}),"\n",(0,r.jsxs)(n.li,{children:["Pixar Animation Studios. (n.d.). ",(0,r.jsx)(n.em,{children:"Universal Scene Description (USD)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["PortAudio. (n.d.). ",(0,r.jsx)(n.em,{children:"PyAudio documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Python Software Foundation. (2023). ",(0,r.jsx)(n.em,{children:"Python 3 Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Quigley, M., et al. (2009). ROS: an open-source Robot Operating System. ",(0,r.jsx)(n.em,{children:"OSROSE. Citeseer"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Radford, A., et al. (2022). Robust Speech Recognition via Large-Scale Weak Supervision. ",(0,r.jsx)(n.em,{children:"arXiv preprint arXiv:2212.04356"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection. ",(0,r.jsx)(n.em,{children:"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["ROS 2 Tutorials. (n.d.). ",(0,r.jsx)(n.em,{children:"Using Parameters in Launch Files"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["ROS 2 Tutorials. (n.d.). ",(0,r.jsx)(n.em,{children:"Using ROS 2 with Gazebo"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["ROS-Industrial Consortium. (n.d.). ",(0,r.jsx)(n.em,{children:"ROS-Industrial Tutorials and Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Rossum, B. (2012). ",(0,r.jsx)(n.em,{children:"Learning ROS for Robotics Programming"}),". Packt Publishing."]}),"\n",(0,r.jsxs)(n.li,{children:["Sadeghi, F., et al. (2016). Cad2rl: Real single-image flight without a single real image. ",(0,r.jsx)(n.em,{children:"Robotics: Science and Systems (RSS) workshop on Learning for Manipulation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Shao, X., et al. (2020). Digital Twin for Autonomous Driving: Challenges and Opportunities. ",(0,r.jsx)(n.em,{children:"IEEE Intelligent Transportation Systems Magazine, 12"}),"(4), 16-29."]}),"\n",(0,r.jsxs)(n.li,{children:["Siciliano, B., & Khatib, O. (Eds.). (2016). ",(0,r.jsx)(n.em,{children:"Springer Handbook of Robotics"}),". Springer."]}),"\n",(0,r.jsxs)(n.li,{children:["Singh, R., et al. (2022). SayCan: Learning Language Grounded Robotic Skills from Natural Language Instructions. ",(0,r.jsx)(n.em,{children:"Conference on Robot Learning (CoRL)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Smith, R., & Chaimowicz, L. (2013). Gazebo tutorials: Understanding physics in Gazebo. ",(0,r.jsx)(n.em,{children:"Open Robotics"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Sutherland, I. E. (1963). SKETCHPAD: A man-machine graphical communication system. ",(0,r.jsx)(n.em,{children:"Massachusetts Institute of Technology, Lincoln Laboratory"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Sutton, R. S., & Barto, A. G. (2018). ",(0,r.jsx)(n.em,{children:"Reinforcement Learning: An Introduction"})," (2nd ed.). MIT Press."]}),"\n",(0,r.jsxs)(n.li,{children:["Svenstrup, M., & Schou, C. (2018). Towards Real-time Simulation of Industrial Robots in Unity. ",(0,r.jsx)(n.em,{children:"Automation 2018: Trends in Automation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Tao, F., & Zhang, M. (2017). Digital Twin manufacturing shop-floor: construction and its applications. ",(0,r.jsx)(n.em,{children:"Computers & Industrial Engineering, 110"}),", 154-165."]}),"\n",(0,r.jsxs)(n.li,{children:["Tobin, J., et al. (2017). Domain randomization for transferring deep neural networks from simulation to the real world. ",(0,r.jsx)(n.em,{children:"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Tremblay, J., et al. (2018). Training deep networks with synthetic data: Bridging the reality gap by domain randomization. ",(0,r.jsx)(n.em,{children:"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Toussaint, M. (2015). ",(0,r.jsx)(n.em,{children:"Robot Motion Planning"}),". Springer."]}),"\n",(0,r.jsxs)(n.li,{children:["Unity Technologies. (n.d.). ",(0,r.jsx)(n.em,{children:"Unity Documentation: High Definition Render Pipeline"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Unity Technologies. (n.d.). ",(0,r.jsx)(n.em,{children:"Unity Robotics Hub Documentation"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Van Rossum, G., & Drake, F. L. (2009). ",(0,r.jsx)(n.em,{children:"Python 3 Reference Manual"}),". CreateSpace."]}),"\n",(0,r.jsxs)(n.li,{children:["Vecerik, M., et al. (2017). Successor features for transfer in reinforcement learning. ",(0,r.jsx)(n.em,{children:"Advances in Neural Information Processing Systems, 30"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Wang, X., et al. (2023). Voyager: An Open-Ended Embodied Agent with Large Language Models. ",(0,r.jsx)(n.em,{children:"arXiv preprint arXiv:2305.16291"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Wollman, D. A. (2014). ",(0,r.jsx)(n.em,{children:"ROS By Example Volume 1: Hydro"}),". CreateSpace Independent Publishing Platform."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>t});var s=i(6540);const r={},o=s.createContext(r);function l(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);